{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to successfully complete this assignment, you must follow all the instructions in this notebook and upload your edited ipynb file to [D2L](http://d2l.msu.edu/) with your answers on or before **10:00am on Friday, November 11th**.\n",
    "\n",
    "**BIG HINT:** Read the entire homework before starting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Projection and diagonalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import sympy as sym\n",
    "import math\n",
    "sym.init_printing(use_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for checking answers\n",
    "import os.path\n",
    "from urllib.request import urlretrieve\n",
    "if not os.path.isfile(\"answercheck.py\"):\n",
    "    urlretrieve('https://raw.githubusercontent.com/colbrydi/jupytercheck/master/answercheck.py', 'answercheck.py');\n",
    "from answercheck import checkanswer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the exponential of a matrix (35 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will learn how to apply the exponential function $e^x$ to a matrix in a way that makes sense.\n",
    "\n",
    "The first step is to use a [fact from calculus](https://www.mathsisfun.com/algebra/taylor-series.html) that we can represent the function $e^x$ by its *Taylor series*, that is, a polynomial with infinitely many terms:\n",
    "\n",
    "$$e^x = \\frac{x^0}{0!} + \\frac{x^1}{1!} + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\ldots + \\frac{x^n}{n!} + \\ldots$$\n",
    "\n",
    "The following function computes the value of this Taylor series where we only use `d` many terms, i.e., use a Taylor polynomial of degree `d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_taylor(x, d):\n",
    "    y = 0.0\n",
    "    for n in range(d + 1):\n",
    "        y += (1 / math.factorial(n)) * x ** n \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 1.1:</font>** (3 pts) Find the smallest degree Taylor polynomial that can compute the value of $e^1 = e$ with enough accuracy that `numpy` cannot distinguish it from `np.e` using `np.isclose`.\n",
    "\n",
    "*(Hint: try using a for loop.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Put your answer to the above question here\n",
    "for x in range(1,100):\n",
    "    val = exp_taylor(x, 50)\n",
    "    is_close = np.isclose(val, np.e)\n",
    "    if is_close == True:\n",
    "        print(x)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got x=1; so the smallest degree taylor polynomial that can compute the value of e^1 = e with enough accuracy that np.isclose() prints true, is 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nice thing about polynomials is that they only use two operations: multiplication and addition. We can do both of these things to matrices! So even though we don't really have a way to compute $e^X$ when $X$ is a matrix, we can compute\n",
    "\n",
    "$$\\frac{X^0}{0!} + \\frac{X^1}{1!} + \\frac{X^2}{2!} + \\frac{X^3}{3!} + \\ldots + \\frac{X^n}{n!} + \\ldots$$\n",
    "\n",
    "(or at least an approximation to it using a finite number of terms). This is the definition of the *matrix exponential* $e^X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 1.2:</font>** (5 pts) Using the function [`np.linalg.matrix_power`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.matrix_power.html), modify the function above to compute the Taylor polynomial of degree `d` using a matrix `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here\n",
    "\n",
    "def exp_taylor_matrix(X, d):\n",
    "    y = 0.0\n",
    "    for n in range(d + 1):\n",
    "        y +=  (1 / math.factorial(n)) * np.linalg.matrix_power(X,n) # MODIFY THIS LINE  np.linalg.matrix_power(X,n)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing [[ 8.965  3.2   -0.497]\n",
      " [ 1.992  0.716 -0.074]\n",
      " [ 3.771  1.352 -0.143]]\n",
      "Answer seems to be correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.matrix([[2, 3, -1], [1, -6, 2], [2, 1, -3]])\n",
    "Y = exp_taylor_matrix(X, 1000) # We use a very high degree to get a good approximation\n",
    "\n",
    "from answercheck import checkanswer\n",
    "checkanswer.matrix(Y,\"ebc8b8e6828a967e5ee6634bf3f003eb\", decimal_accuracy=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 1.3:</font>** (5 pts) Compare your result to applying `numpy`'s exponential function [`np.exp`](https://numpy.org/doc/stable/reference/generated/numpy.exp.html) to the matrix $X$. Why are the results not equal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[7.38905610e+00, 2.00855369e+01, 3.67879441e-01],\n",
       "        [2.71828183e+00, 2.47875218e-03, 7.38905610e+00],\n",
       "        [7.38905610e+00, 2.71828183e+00, 4.97870684e-02]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put your code for the above question here \n",
    "X = np.matrix([[2, 3, -1], [1, -6, 2], [2, 1, -3]])\n",
    "np.exp(X)\n",
    "\n",
    "#np.exp(X), exp_taylor_matrix(X,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.exp is a function that takes the exponential of each element instead of actually doing the matrix multiplication as many times as needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we have a way to take the exponential of a matrix. However, as we learned, matrix multiplication is $O(n^3)$ for an $n \\times n$ matrix, and this gets expensive when you're doing it over and over to compute the powers of a matrix.\n",
    "\n",
    "But section 3 of ICA 15 gave us another way to compute powers of matrices. We will use this to create a faster `exp_taylor_matrix` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any diagonalizable matrix $X$, we can find two matrices $C$ and $D$ where $D$ is diagonal such that\n",
    "\n",
    "$$X = CDC^{-1}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 1.4:</font>** (5 pts) Explain in words what $C$ and $D$ are and how you would compute them in `numpy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C is the eigenvector matrix of X where the columns are the basis/eigenvectors.\n",
    "D is a diagonal matrix w/ the diagonal values representing non zero values, each column of  C is a linearly independent eigenvector of D. Using the numpy np.linalg.eig(X) and letting the results equal the values that go on. the diag for D and C. then taking the inverse of c gives you c^-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the fact that $I = C^{-1}C$, repeated multiplication gives\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "X^n \n",
    "    &= (CDC^{-1})^n \\\\\n",
    "    &= CDC^{-1} \\times CDC^{-1} \\times CDC^{-1} \\\\\n",
    "    &= CD(C^{-1}C)D(C^{-1}C) \\cdots (C^{-1}C)DC^{-1} \\\\\n",
    "    &= CDIDI \\cdots IDC^{-1} \\\\\n",
    "    &= CD^nC^{-1}.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 1.5:</font>** (6 pts)\n",
    "\n",
    "Define the polynomial (of matrices)\n",
    "\n",
    "$$p(X) = I + X + 2 X^2 + 3 X^3.$$\n",
    "\n",
    "Using the distributive property of matrix multiplication and the power property above, show that if $X$ is diagonalizable, then\n",
    "\n",
    "$$ p(X) = C \\times p(D) \\times C^{-1} .$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"importthis.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "img = 'importthis.png'\n",
    "Image(url=img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 1.6:</font>** (6 pts) For the diagonal matrix\n",
    "$D = \n",
    "\\begin{bmatrix}\n",
    "    \\lambda_1 & 0 \\\\\n",
    "    0 & \\lambda_2\n",
    "\\end{bmatrix}\n",
    "$, using the fact that\n",
    "$D^n = \n",
    "\\begin{bmatrix}\n",
    "    \\lambda_1^n & 0 \\\\\n",
    "    0 & \\lambda_2^n\n",
    "\\end{bmatrix},\n",
    "$\n",
    "\n",
    "show that\n",
    "\n",
    "$$p(D) = \\begin{bmatrix}\n",
    "            p(\\lambda_1) & 0 \\\\\n",
    "            0 & p(\\lambda_2)\n",
    "         \\end{bmatrix}$$\n",
    "         \n",
    "(where $p$ works on numbers instead of matrices by replacing the identity $I$ with $1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"importthistoo.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "img2 = 'importthistoo.png'\n",
    "Image(url=img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the same thing is true for the Taylor series of $e^x$. That is, if \n",
    "\n",
    "$$p(X) = \\frac{X^0}{0!} + \\frac{X^1}{1!} + \\frac{X^2}{2!} + \\frac{X^3}{3!} + \\ldots + \\frac{X^n}{n!} + \\ldots $$\n",
    "\n",
    "then\n",
    "\n",
    "$$p(X) = C \\times p(D) \\times C^{-1} \n",
    "= C\n",
    "\\begin{bmatrix}\n",
    "p(\\lambda_1) & 0 & 0 & 0 \\\\\n",
    "0 & p(\\lambda_2) & 0 & 0\\\\\n",
    "0 & 0 & \\ddots & 0 \\\\\n",
    "0 & 0 & 0 & p(\\lambda_n)\n",
    "\\end{bmatrix}\n",
    "C^{-1}$$\n",
    "But if we remember that the Taylor series is equal to the exponential function, that is, $p(\\lambda_i) = e^{\\lambda_i}$, we have\n",
    "$$e^X = p(X) \n",
    "= C\n",
    "\\begin{bmatrix}\n",
    "e^{\\lambda_1} & 0 & 0 & 0 \\\\\n",
    "0 & e^{\\lambda_2} & 0 & 0\\\\\n",
    "0 & 0 & \\ddots & 0 \\\\\n",
    "0 & 0 & 0 & e^{\\lambda_n}\n",
    "\\end{bmatrix} C^{-1}.\n",
    " $$\n",
    " \n",
    "So let's put this all together to write a faster `exp_taylor_matrix` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 1.7:</font>** (5 pts) Fill in the code in the following function. Add any lines where you need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faster_exp_taylor_matrix(X):\n",
    "    #eigenvals = np.eigvals(X)# FIND EIGENVALUES\n",
    "    eigenvals, C = np.linalg.eig(X)\n",
    "    expD = np.diag(np.exp(eigenvals))\n",
    "    Y = C @ expD @ np.linalg.inv(C)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun the test from before to check your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing [[ 8.965  3.2   -0.497]\n",
      " [ 1.992  0.716 -0.074]\n",
      " [ 3.771  1.352 -0.143]]\n",
      "Answer seems to be correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.matrix([[2, 3, -1], [1, -6, 2], [2, 1, -3]])\n",
    "Y = faster_exp_taylor_matrix(X)\n",
    "\n",
    "\n",
    "from answercheck import checkanswer\n",
    "checkanswer.matrix(Y,\"ebc8b8e6828a967e5ee6634bf3f003eb\", decimal_accuracy=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the faster function is indeed faster! For larger matrices and higher degree polynomials, this would make even more of a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original function time: 0.004774570465087891 seconds\n",
      "Faster function time: 0.00028967857360839844 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run this cell!\n",
    "\n",
    "import time\n",
    "t_start = time.time()\n",
    "Y = exp_taylor_matrix(X, 100)\n",
    "print(\"Original function time:\", time.time() - t_start, \"seconds\")\n",
    "t_start = time.time()\n",
    "Y = faster_exp_taylor_matrix(X)\n",
    "print(\"Faster function time:\", time.time() - t_start, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Projection (35 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the vector $v=[-2,1,3]^\\top$ and the plane $W = \\{[x_1,x_2,x_3]^\\top: x_1+x_2-x_3=0\\},$ in\n",
    "$\\mathbb{R}^3$, we want to find the projection of $v$ onto $W$ using the following steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 2.1:</font>** (5 pts) \n",
    "Use the equation defining the plane to solve for $x_1$ in terms of $x_2$ and $x_3$. Use this to write the vectors in $W$ depending on just the values $x_2$ and $x_3$.\n",
    "\n",
    "(*Hint: This is very similar to solving for the nullspace of a matrix where you have two free variables.*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 2.2:</font>** (5 pts)\n",
    "Rewrite this your answer to QUESTION 2.1 to be a linear combination of the form $x_2 v_1 + x_3 v_2$, where $v_1$ and $v_2$ are vectors.\n",
    "\n",
    "Check your values of $v_1$ and $v_2$ below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your answer for the above question here\n",
    "v1 = [-0.7, 0.7, 0]\n",
    "v2 =  [0.7, 0, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CheckWarning: passed variable is <class 'numpy.ndarray'> and not a numpy.matrix.\n",
      "    Trying to convert to a array matrix using ```A = np.matrix(A)```.\n",
      "\n",
      "\n",
      "CheckWarning: Vector contains negative values for zero...\n",
      "    Converting to positive values of zero using  ```A[A==-0] = 0```.\n",
      "\n",
      "Testing [[-0.70711  0.70711  0.     ]]\n",
      "Answer seems to be correct\n",
      "\n",
      "\n",
      "CheckWarning: passed variable is <class 'numpy.ndarray'> and not a numpy.matrix.\n",
      "    Trying to convert to a array matrix using ```A = np.matrix(A)```.\n",
      "\n",
      "\n",
      "CheckWarning: Vector contains negative values for zero...\n",
      "    Converting to positive values of zero using  ```A[A==-0] = 0```.\n",
      "\n",
      "Testing [[0.70711 0.      0.70711]]\n",
      "Answer seems to be correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from answercheck import checkanswer\n",
    "checkanswer.vector(v1 / np.linalg.norm(v1),\"2a0160bf571ec2047b7cb0355066aa24\");\n",
    "checkanswer.vector(v2 / np.linalg.norm(v2),\"0d5dd28ffe9384507c3378da18db6869\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 2.3:</font>** (5 pts)\n",
    "Check that `v1` and `v2` are linearly independent. You may either do this by hand or using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAD4AAAASCAYAAAADr20JAAACsUlEQVR4nO3XTYhWZRQH8N9bY9iHn4G0UEQHM5HAxBzFVQqzcCGRW4csWkShVroyslEI2ozfBqaVoguVcBWIRgTSxxBELtJIGR1cuBBbpGPjMKktznN7b++8t7mj19V44OHce87/Pc9z7nO+3lpnZ6fRSI88AJtT8TmuYAC92I5J92m3A3fTeqMAU8Pr6MYN/IVfsBaP5oFVO96Kn/EafsI2XMQ6/Iin79HuNOxC3zC4g/gMM3AU+/AYdqT3WgZsuceDFNEnmCK+8K6cfCvexUd4c4Q2a/gCf+A4NhTgXhZRcQkLcS3Jx+AYVuJVHKDaG5+JdhHaexp0H+JmOtiTI7S7FktFFN38H9wriXepOw2D+CA9r8mEVTq+NPFTuNOgu4Hv8QQWjcDmHHwsQvX0MNhnEr/YRJfJ5mMi1To+O/HzBfoLiT9b0l4LDuEyNpbAZ7c8o4luZu75Oap1fELifxboM/nEkvY24QWsRn8J/FeJv4fJOXkLNufeJzHU8V71llFmHS7pBPWKercEdqG45S7RDcrQEZwQneUcPhVt9AyWq0fcbYZW9R7cKrkR0aszym50QjMgxjfgiigL8fPqRakM3cEK0To70hrED6Ka78YsXM02ydOyEWzUSL8nXpTDsxIvqgEZPZWzUXQJ+9LagXdy8r9FlHQ14B/HPJEyZ6m2j3+beLtIoXxlH4claePuYewMiCGkGc0Xef+d+NBl06ADY8WAM0i1jveIVtaOt/13gNks+vdeQ3txqxgyetKh+hWPpJ3C8YPY30Q/HtcbZC+KltiHLZmw6sntLZFTO0Xa/IY2vCRC/P0mv/kG00Ub6r3P/b8WH+5XMTvMFYVtQAw4//b4qmf1HiwQY2Eb1osb3YnFYux8kPSlSKtVoq09LyJjLk7mgbWHf0tHGY1ax/8B/z2Y2oCZgQwAAAAASUVORK5CYII=\n",
      "text/latex": [
       "$\\displaystyle -0.49$"
      ],
      "text/plain": [
       "-0.48999999999999994"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this cell for an answer with Python (leave blank if doing by hand)\n",
    "np.linalg.norm(v1)\n",
    "np.linalg.norm(v2)\n",
    "np.dot(v1,v2) #not zero, so orthogonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show that they’re not orthonormal, compute the norm of each vector to show that they’re length not 1. Then you also need to show that the vectors are not orthogonal with each other, so compute the dot product between the two vectors and show that it’s not equal to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that these two vectors are a basis for $W$, but you can check that they are not orthonormal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 2.4:</font>** (5 pts)\n",
    "Since an orthonormal basis is easier to work with, orthogonalize `v1` and `v2` by applying the Gram-Schmidt process. Store the resulting orthonormal vectors as `w1` and `w2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your answer to the above question here\n",
    "w1 = (-np.sqrt(2)/2,np.sqrt(2)/2,0)\n",
    "w2 =(-np.sqrt(6)/2,np.sqrt(6)/6, np.sqrt(6)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 2.5:</font>** (5 pts) Use python to verify that {`w1`,`w2`} is indeed an orthonormal basis of the plane $W$. Specifically, verify\n",
    "\n",
    "-  each basis vector has unit length \n",
    "-  orthogonality between different basis vectors.\n",
    "-  `w1`, `w2` $\\in W$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your answer to the above question here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in Pre-class 13, the following mathematical definition of projection onto a subspace is defined.\n",
    "\n",
    "**Definition**: Let $W$ be a subspace of $R^n$ of dimension $m$. Let $\\{w_1,\\cdots,w_m\\}$ be an orthonormal basis for $W$. Then the projection of vector $v$ in $R^n$ onto $W$ is denoted as $\\mbox{proj}_Wv$ and is defined as \n",
    "$$\\mbox{proj}_Wv = (v\\cdot w_1)w_1+(v\\cdot w_2)w_2+\\cdots+(v\\cdot w_m)w_m$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 2.6:</font>** (5 pts) Use this formula to find $P_w v$, the projection of $v=[-2,1,3]^T$ onto $W$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'numpy.float64'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-a6e9a7f83c58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Put your answer to the above question here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mPwv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'numpy.float64'"
     ]
    }
   ],
   "source": [
    "# Put your answer to the above question here\n",
    "Pwv = (np.dot(v1, w1)* w1) + (np.dot(v1, w2)* w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pwv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-33b5c90f4860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manswercheck\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheckanswer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheckanswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPwv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"02b1f7fc612d9c4721e21e45f4444688\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Pwv' is not defined"
     ]
    }
   ],
   "source": [
    "from answercheck import checkanswer\n",
    "checkanswer.vector(Pwv,\"02b1f7fc612d9c4721e21e45f4444688\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 2.7:</font>** (5 pts) What is the geometric meaning of $v-P_W v$? Use this to find the distance from $v$ to $W$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v⊥ = v − projwv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-d99dfd99213f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Put your code to find the distance here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'w1' is not defined"
     ]
    }
   ],
   "source": [
    "# Put your code to find the distance here\n",
    "distance = (abs(w1*v1 + w1*v2)) / (np.sqrt( w1*w1 + w2*w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from answercheck import checkanswer\n",
    "checkanswer.matrix(distance,\"dd5b8b47bdfbbad36cedf5ee17fe60b1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Properties of orthogonal matrices (30 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pre-class 13, we learned the definition of orthogonal matrices. Let us  review it here.\n",
    "\n",
    "**Definition:** A $n\\times n$ matrix $U$ is orthogonal if the columns of $U$ form an orthonormal basis of  $\\mathbb {R} ^{n}$.\n",
    "\n",
    "Orthogonal matrices have many alternative definitions. Explictly, the following conditions are all equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $U$ is orthogonal\n",
    "\n",
    "2. the rows of $U$ form an orthonormal basis of $\\mathbb{R}^{n}$.\n",
    "\n",
    "3. the columns of $U$ form an orthonormal basis of $\\mathbb{R}^{n}$.\n",
    "\n",
    "4. U is invertible, and $U^T = U^{-1}$.\n",
    "\n",
    "5. For any two vectors $x$ and $y$ in $\\mathbb{R}^n$, multiplication by $U$ preserves their dot product; that is, $(Ux)\\cdot (Uy) = x \\cdot y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 3.1:</font>** (5 pts) Let $v_1 = \\left[\\frac{1}{\\sqrt 2}, 0, \\frac{1}{\\sqrt 2}\\right]$, $v_2 = [0, 1, 0]$, $v_3 = \\left[\\frac{1}{\\sqrt 2}, 0, -\\frac{1}{\\sqrt 2}\\right]$.\n",
    "\n",
    "Use one of conditions 2, 3, or 4 above to verify that $v_1,v_2,v_3$ form an orthonormal basis of $\\mathbb{R}^3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.70710678  0.          0.70710678]\n",
      " [ 0.          1.          0.        ]\n",
      " [ 0.70710678  0.         -0.70710678]]\n",
      "[[ 0.70710678  0.          0.70710678]\n",
      " [ 0.          1.          0.        ]\n",
      " [ 0.70710678 -0.         -0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "# Put your answer for the above question here\n",
    "\n",
    "v1 = np.matrix([[1/np.sqrt(2),0,1/np.sqrt(2)]])\n",
    "v2 = np.matrix([[0,1,0]])\n",
    "v3 = np.matrix([[1/np.sqrt(2),0,-1/np.sqrt(2)]])\n",
    "U = np.matrix([[1/np.sqrt(2),0,1/np.sqrt(2)],[0,1,0],[1/np.sqrt(2),0,-1/np.sqrt(2)]])\n",
    "print(U.T)\n",
    "print(np.linalg.inv(U)) #equal so 4 holds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 3.2:</font>** (5 pts) Use python code  to construct the following two $3\\times 3$ transformation matrices: \n",
    "+ Rotation matrix `R` that rotates a given vector in $\\mathbb{R}^3$ around the $y$-axis counterclockwise by an angle of $40^\\circ$ \n",
    "+ Reflection matrix `F` that reflects a given vector in $\\mathbb{R}^3$ with respect to the $x$-$y$ plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your answer for the above question here\n",
    "R = np.matrix([[np.cos(40),np.sin(40),0],\n",
    "          [-np.sin(40),np.cos(40),0],\n",
    "          [0,0,1]])\n",
    "\n",
    "# R = np.matrix([[np.cos(40),0,np.sin(40)],\n",
    "#                [0,1,0],\n",
    "#                [-np.sin(40),0,np.cos(40)]])\n",
    "\n",
    "F = np.matrix([[1,0,0],[0,1,0],[0,0,-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 3.3:</font>** (5 pts) It is a fact that the product of orthogonal matrices is also an orthogonal matrix. Verify that `R`,`F` and their products `RF`, `FRFR` are all orthogonal matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.66693806  0.74511316  0.        ]\n",
      " [-0.74511316 -0.66693806  0.        ]\n",
      " [ 0.          0.          1.        ]]\n",
      "[[ 1  0  0]\n",
      " [ 0  1  0]\n",
      " [ 0  0 -1]]\n",
      "[[-0.66693806  0.74511316  0.        ]\n",
      " [-0.74511316 -0.66693806  0.        ]\n",
      " [ 0.          0.         -1.        ]]\n",
      "[[-0.11038724 -0.99388865  0.        ]\n",
      " [ 0.99388865 -0.11038724  0.        ]\n",
      " [ 0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Put your answer for the above question here\n",
    "print(R)\n",
    "print(F)\n",
    "RF = R*F\n",
    "print(RF)\n",
    "FRFR = F*R*F*R\n",
    "print(FRFR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 3.4:</font>** (5 pts) Rotations and reflections are known as rigid motions, meaning that they do not change the length of the vectors being rotated/reflected. This is in fact an intrinsic property of orthogonal matrices and is guaranteed by one of the equivalent conditions of orthogonal matrices listed above. Which condition is that? Be sure to explain your reasoning.\n",
    "\n",
    "(*Hint: for an orthogonal matrix $U$, when we say it does not change the length of the input, we mean $\\|Ux\\|=\\|x\\|$ for any $x$, that is, the length of $Ux$ is always the same as the length of $x$. You are asked to find the condition of orthogonal matrices that implies this.*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "𝑈  is orthogonal\n",
    "\n",
    "the rows of  𝑈  form an orthonormal basis of  ℝ𝑛 .\n",
    "\n",
    "the columns of  𝑈  form an orthonormal basis of  ℝ𝑛 .\n",
    "\n",
    "U is invertible, and  𝑈𝑇=𝑈−1 .\n",
    "\n",
    "For any two vectors  𝑥  and  𝑦  in  ℝ𝑛 , multiplication by  𝑈  preserves their dot product; that is,  (𝑈𝑥)⋅(𝑈𝑦)=𝑥⋅𝑦 \n",
    "\n",
    "So by both conditions (the rows of  𝑈  form an orthonormal basis of  ℝ𝑛 and the columns of  𝑈  form an orthonormal basis of  ℝ𝑛) it implied that since the rows and columns of ℝ𝑛 each form orthonormal basis' that the length of Ux will be the length of x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 3.5:</font>** (5 pts) Find values $a,b,c,d,e,f$ such that\n",
    "$$A = \\begin{bmatrix}\n",
    "0.6 & a & b \\\\\n",
    "c & 1 & d \\\\\n",
    "0.8 & e & f\n",
    "\\end{bmatrix}$$\n",
    "is orthogonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0 \n",
    "b = -4/5\n",
    "c = 0 \n",
    "d = 0 \n",
    "e = 0 \n",
    "f =3/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CheckWarning: passed variable is <class 'list'> and not a numpy.matrix.\n",
      "    Trying to convert to a array matrix using ```A = np.matrix(A)```.\n",
      "\n",
      "\n",
      "CheckWarning: Vector contains negative values for zero...\n",
      "    Converting to positive values of zero using  ```A[A==-0] = 0```.\n",
      "\n",
      "Testing [[ 0.    0.8   0.    0.    0.   -0.48]]\n",
      "Answer seems to be correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from answercheck import checkanswer\n",
    "checkanswer.vector([a,abs(b),c,d,e,f*b], \"d59ddb576ffec29ace7f2a08bfd694d2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION 3.6:</font>** (5 pts) Compute the eigenvalues of all four of the orthogonal matrices mentioned in QUESTION 3.3, what did you find about the magnitudes of these eigenvalues? Could you come up with a theoretical explanation for this phenomenon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-0.666938061652262 - 0.745113160479349*I: 1, -0.666938061652262 + 0.745113160479349*I: 1, 1.00000000000000: 1}\n",
      "{1: 2, -1: 1}\n",
      "{-0.666938061652262 - 0.745113160479349*I: 1, -0.666938061652262 + 0.745113160479349*I: 1, -1.00000000000000: 1}\n",
      "{-0.110387243839048 - 0.993888653923375*I: 1, -0.110387243839048 + 0.993888653923375*I: 1, 1.00000000000000: 1}\n"
     ]
    }
   ],
   "source": [
    "# Put your answer for the above question here\n",
    "R = sym.Matrix(R)\n",
    "F = sym.Matrix(F)\n",
    "RF = sym.Matrix(RF)\n",
    "FRFR = sym.Matrix(FRFR)\n",
    "\n",
    "\n",
    "print(R.eigenvals())\n",
    "print(F.eigenvals())\n",
    "print(RF.eigenvals())\n",
    "print(FRFR.eigenvals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first matrix, the eigenvalues are less than one so the magnitude of the vector gets smaller than the original magnitude by a reasonable percentage. For the second matrix, the eigenvalues are 1 and -1 so the magnitude is the same for the 1 and became smaller for the -1. for the third matrix, it is the same as the first. for the fourht matrix the eigenvalues are less than one so the magnitude of the vector gets smaller than the original magnitude by a reasonable percentage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations, we're done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
